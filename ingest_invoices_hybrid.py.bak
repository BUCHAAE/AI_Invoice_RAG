"""
Author: Andrew Buchanan
Date: 26/04/2025

Purpose:
Processes structured CSVs for invoices and attendance records. It builds a vectorstore enriched
with summaries (e.g. total invoices, years attended, total billed) to ensure factual answers from the LLM.
"""

import os
import pandas as pd
from datetime import datetime
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_community.vectorstores import Chroma
from langchain.text_splitter import RecursiveCharacterTextSplitter

# --- Configuration ---
persist_directory = "chroma_db"
invoice_csv = "invoice_summary.csv"
attendance_csv = "attendance_detail.csv"
embedding_model_name = "BAAI/bge-small-en"

# --- Load and validate CSVs ---
if not os.path.exists(invoice_csv) or not os.path.exists(attendance_csv):
    raise FileNotFoundError("Missing invoice or attendance CSVs")

invoice_df = pd.read_csv(invoice_csv)
attendance_df = pd.read_csv(attendance_csv)

# Parse dates
attendance_df["ParsedDate"] = pd.to_datetime(attendance_df["Date"], format="%d/%m/%Y", errors="coerce")
attendance_df = attendance_df.dropna(subset=["ParsedDate"])

# --- Static Facts ---
print("üìä Generating static facts...")
static_context = []

# Years
invoice_df["Year"] = invoice_df["MonthBilledFor"].apply(lambda x: x.split()[1] if isinstance(x, str) and " " in x else None)
years_attended = sorted(invoice_df["Year"].dropna().unique())
static_context.append(f"Snoopy attended doggy daycare during these years: {', '.join(years_attended)}.")

# Invoice totals
invoice_count = len(invoice_df)
static_context.append(f"There are {invoice_count} invoices in total.")

# Total cost
invoice_df["TotalAmountDue"] = pd.to_numeric(invoice_df["TotalAmountDue"], errors='coerce')
total_cost = invoice_df["TotalAmountDue"].sum()
static_context.append(f"The total billed amount across all invoices is ${total_cost:.2f}.")

# First attendance
if not attendance_df.empty:
    first_attendance = attendance_df["ParsedDate"].min()
    static_context.append(f"Snoopy's first daycare attendance was on {first_attendance.strftime('%d/%m/%Y')}.")

# --- Merge invoice + attendance rows ---
print("üìÑ Generating document chunks...")

documents = []

# Add static facts to documents
documents.extend(static_context)

# Add attendance details
for _, row in attendance_df.iterrows():
    documents.append(
        f"{row['DogName']} attended on {row['Date']} ({row['Day']}) under invoice {row['InvoiceNumber']}."
    )

# Chunking
splitter = RecursiveCharacterTextSplitter(chunk_size=400, chunk_overlap=50)
chunks = splitter.split_text("\n".join(documents))
print(f"‚úÇÔ∏è Split into {len(chunks)} text chunks.")

# Embeddings + vectorstore
if os.path.exists(persist_directory):
    import shutil
    shutil.rmtree(persist_directory)

embedding = HuggingFaceEmbeddings(model_name=embedding_model_name)
vectorstore = Chroma.from_texts(chunks, embedding=embedding, persist_directory=persist_directory)

print("‚úÖ Vectorstore built and saved.")
